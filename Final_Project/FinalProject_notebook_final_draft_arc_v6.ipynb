{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Environment Setup\n",
    "import arcpy\n",
    "import arcpy.mp\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benla\\Desktop\\Grad_School\\Classes\\GIS5571_SpatialDataScience\\Final_Project\\Data\n"
     ]
    }
   ],
   "source": [
    "## Step 2: Data Setup\n",
    "\n",
    "# Set working directory\n",
    "arcpy.env.workspace = r\"C:\\Users\\benla\\Desktop\\Grad_School\\Classes\\GIS5571_SpatialDataScience\\Final_Project\\Data\"\n",
    "print(arcpy.env.workspace)\n",
    "\n",
    "# Set defautlt gdb path\n",
    "gdb_path =  r\"C:\\Users\\benla\\Desktop\\Grad_School\\Classes\\GIS5571_SpatialDataScience\\Final_Project\\FinalProject_aprx\\Default.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n",
      "File unzipped successfully\n"
     ]
    }
   ],
   "source": [
    "## Step 2: Data Setup\n",
    "\n",
    "# Get request to download Hennepin County parcels dataset\n",
    "\n",
    "# Define the download path\n",
    "parcels_path = os.path.join(arcpy.env.workspace, \"County_Parcels.zip\")\n",
    "\n",
    "# Make the get request\n",
    "response = requests.get(\"https://hub.arcgis.com/api/v3/datasets/7975aabf6e1e42998a40a4b085ffefdf_1/downloads/data?format=shp&spatialRefId=26915&where=1%3D1\")\n",
    "\n",
    "# Write the response content to a file\n",
    "with open(parcels_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "print(\"File downloaded successfully\")\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(parcels_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(arcpy.env.workspace)\n",
    "print(\"File unzipped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n",
      "File unzipped successfully\n"
     ]
    }
   ],
   "source": [
    "## Step 2: Data Setup\n",
    "\n",
    "# Get request to download census tracts shapefile for 7-county metro area\n",
    "\n",
    "# Define the download path\n",
    "census_tracts_path = os.path.join(arcpy.env.workspace, \"Census_Tracts.zip\")\n",
    "\n",
    "# Make the get request\n",
    "response = requests.get(\"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census2020tiger/shp_society_census2020tiger.zip\")\n",
    "\n",
    "# Write the response content to a file\n",
    "with open(census_tracts_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "print(\"File downloaded successfully\")\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(census_tracts_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(arcpy.env.workspace)\n",
    "print(\"File unzipped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n",
      "File unzipped successfully\n"
     ]
    }
   ],
   "source": [
    "## Step 2: Data Setup\n",
    "\n",
    "# Get request to download pollution source point data from My Neighborhood Sites (MPCA)\n",
    "\n",
    "# Define the download path\n",
    "pollution_data_path = os.path.join(arcpy.env.workspace, \"Pollution_Data.zip\")\n",
    "\n",
    "# Make the get request\n",
    "response = requests.get(\"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_pca/env_my_neighborhood/shp_env_my_neighborhood.zip\")\n",
    "\n",
    "# Write the response content to a file\n",
    "with open(pollution_data_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "print(\"File downloaded successfully\")\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(pollution_data_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(arcpy.env.workspace)\n",
    "print(\"File unzipped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n",
      "File unzipped successfully\n"
     ]
    }
   ],
   "source": [
    "## Step 2: Data Setup\n",
    "\n",
    "# Get request to download Hennepin County poverty dataset from MN Department of Health\n",
    "\n",
    "# Define the download path\n",
    "poverty_data_path = os.path.join(arcpy.env.workspace, \"Poverty_Data.zip\")\n",
    "\n",
    "# Make the get request\n",
    "response = requests.get(\"https://mndatamaps.web.health.state.mn.us/interactive/data/zip/PovertyTractData.zip\")\n",
    "\n",
    "# Write the response content to a file\n",
    "with open(poverty_data_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "print(\"File downloaded successfully\")\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(poverty_data_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(arcpy.env.workspace)\n",
    "print(\"File unzipped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Data Setup\n",
    "\n",
    "# Read input datasets\n",
    "parcels_full = r\"County_Parcels.shp\"\n",
    "pollution_sources_full = r\"my_neighborhood_sites.shp\"\n",
    "census_tracts = r\"Census2020TigerTract.shp\"\n",
    "poverty_csv = r\"./PovertyTractData/PovertyTract2019.csv\"\n",
    "demographics_csv = r\"CensusTract_Demographic_Data.csv\"\n",
    "GEMS_lab_data = r\"full_parcels_ranked_final_v1.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Tuesday, December 17, 2024 6:26:24 PM<br>Analyzing input features...<br>Dissolving clip features...<br>Clipping input features...<br>Succeeded at Tuesday, December 17, 2024 6:27:28 PM (Elapsed Time: 1 minutes 4 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\benla\\\\Desktop\\\\Grad_School\\\\Classes\\\\GIS5571_SpatialDataScience\\\\Final_Project\\\\Data\\\\pollution_source_points_hennepin.shp'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 2: Data Setup\n",
    "\n",
    "# Create feature layers\n",
    "arcpy.MakeFeatureLayer_management(parcels_full, \"parcels_layer\")\n",
    "\n",
    "# Get the extent of the parcels layer\n",
    "extent = arcpy.Describe(\"parcels_layer\").extent\n",
    "\n",
    "# Clip pollution source points to the extent of parcels\n",
    "arcpy.analysis.Clip(\n",
    "    in_features=pollution_sources_full,\n",
    "    clip_features=\"parcels_layer\",\n",
    "    out_feature_class=\"pollution_source_points_hennepin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Tuesday, December 17, 2024 6:31:54 PM<br>Succeeded at Tuesday, December 17, 2024 6:32:13 PM (Elapsed Time: 19.34 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'parcels_with_pollution_count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "## Count pollution source points within each parcel, if no points within parcel, calculate distance to nearest pollution point \n",
    "# Perform Spatial Join to count points within each polygon\n",
    "output_layer=\"parcels_with_pollution_count\"\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features= \"parcels_layer\",\n",
    "    join_features=\"pollution_source_points_hennepin\",\n",
    "    out_feature_class=output_layer,\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    match_option=\"CONTAINS\",\n",
    "    field_mapping=arcpy.FieldMappings()\n",
    ")\n",
    "\n",
    "# Add a new field for point count and another for nearest distance IF no points within parcel\n",
    "arcpy.management.AddField(output_layer, \"pts_in\", \"LONG\")\n",
    "arcpy.management.AddField(output_layer, \"dist_near\", \"DOUBLE\")\n",
    "\n",
    "# Calculate the count of points within each polygon\n",
    "arcpy.management.CalculateField(\n",
    "    in_table=output_layer,\n",
    "    field=\"pts_in\",\n",
    "    expression=\"!Join_Count!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parcels processed: 446534\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "# Select polygons with zero points\n",
    "zero_points_layer = \"zero_points_layer\"\n",
    "arcpy.management.MakeFeatureLayer(output_layer, zero_points_layer, \"pts_in = 0\")\n",
    "\n",
    "# Calculate the nearest distance for polygons with zero points\n",
    "arcpy.analysis.Near(\n",
    "    in_features=zero_points_layer,\n",
    "    near_features=\"pollution_source_points_hennepin\",\n",
    "    search_radius=\"\",\n",
    "    location=\"NO_LOCATION\",\n",
    "    angle=\"NO_ANGLE\",\n",
    "    method=\"PLANAR\"\n",
    ")\n",
    "\n",
    "# Update the main output layer with nearest distance\n",
    "with arcpy.da.UpdateCursor(output_layer, [\"pts_in\", \"NEAR_DIST\", \"dist_near\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] == 0:  # If pts_in is 0\n",
    "            row[2] = row[1]  # Set dist_near to NEAR_DIST value\n",
    "        else:\n",
    "            row[2] = 0.0  # Set dist_near to 0.0 if there are points within the polygon\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# Verify the result\n",
    "result_count = int(arcpy.GetCount_management(output_layer).getOutput(0))\n",
    "print(f\"Number of parcels processed: {result_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unwanted fields removed, 'zero_points_layer' and 'parcels_sample' deleted.\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "## Clean parcel + pollution data\n",
    "# List of fields to keep\n",
    "fields_to_keep = ['FID', 'Shape', 'OBJECTID', 'PID', 'LAT', 'LON', 'ShapeSTAre', 'ShapeSTLen', 'pts_in', 'dist_near']\n",
    "\n",
    "# List all fields in the output layer\n",
    "all_fields = [f.name for f in arcpy.ListFields(output_layer)]\n",
    "\n",
    "# Identify fields to delete (fields not in the keep list)\n",
    "fields_to_delete = [f for f in all_fields if f not in fields_to_keep]\n",
    "\n",
    "# Delete unwanted fields\n",
    "if fields_to_delete:\n",
    "    arcpy.management.DeleteField(output_layer, fields_to_delete)\n",
    "\n",
    "# Delete the zero_points_layer and original parcels_sample from the map\n",
    "if arcpy.Exists(\"zero_points_layer\"):\n",
    "    arcpy.management.Delete(\"zero_points_layer\")\n",
    "if arcpy.Exists(\"parcels_sample\"):\n",
    "    arcpy.management.Delete(\"parcels_sample\")\n",
    "\n",
    "print(f\"Unwanted fields removed, 'zero_points_layer' and 'parcels_sample' deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filtered and renamed data has been successfully written to the new table, original table deleted.\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "## Bring in poverty data and simultaneously filter it for Hennepin County and clean the data\n",
    "# Define the path to the CSV file and the output table name\n",
    "pov_output_table = \"Poverty_data_table\"\n",
    "\n",
    "# Convert CSV to Arc Table \n",
    "arcpy.TableToTable_conversion(poverty_csv, gdb_path, pov_output_table)\n",
    "\n",
    "# Create new table for Hennepin County poverty data only\n",
    "hennepin_pov_table = \"Hennepin_pov_data\"\n",
    "hennepin_pov_table_path = os.path.join(gdb_path, hennepin_pov_table)\n",
    "arcpy.CreateTable_management(gdb_path, hennepin_pov_table)\n",
    "\n",
    "# Add fields to Hennepin poverty data table\n",
    "arcpy.AddField_management(hennepin_pov_table_path, \"povdata_FIPS\", \"TEXT\")\n",
    "arcpy.AddField_management(hennepin_pov_table_path, \"County\", \"TEXT\")\n",
    "arcpy.AddField_management(hennepin_pov_table_path, \"Num_in_Pov\", \"LONG\")\n",
    "arcpy.AddField_management(hennepin_pov_table_path, \"Pct_in_Pov\", \"DOUBLE\")\n",
    "arcpy.AddField_management(hennepin_pov_table_path, \"State_Comp\", \"TEXT\")\n",
    "\n",
    "# Use a search cursor to filter rows for 'Hennepin' and an insert cursor to add the data to the new table\n",
    "with arcpy.da.SearchCursor(\"Poverty_data_table\", ['FIPS', 'PrimaryCounty', 'AllAgesCount', 'AllAgesPct', 'AllAgesSigText']) as search_cursor:\n",
    "    with arcpy.da.InsertCursor(hennepin_pov_table_path, ['povdata_FIPS', 'County','Num_in_Pov', 'Pct_in_Pov', 'State_Comp']) as insert_cursor:\n",
    "        for row in search_cursor:\n",
    "            # Check if the row is from Hennepin County\n",
    "            if row[1] == 'Hennepin':\n",
    "                # Insert the filtered and renamed data into the new table\n",
    "                insert_cursor.insertRow((row[0], row[1], row[2], row[3], row[4]))\n",
    "\n",
    "if arcpy.Exists(\"Poverty_data_table\"):\n",
    "    arcpy.management.Delete(\"Poverty_data_table\")\n",
    "\n",
    "print(\"The filtered and renamed data has been successfully written to the new table, original table deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Tuesday, December 17, 2024 6:55:57 PM<br>Succeeded at Tuesday, December 17, 2024 6:55:58 PM (Elapsed Time: 0.16 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'Demographics_data_table'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "## Bring in demographics data\n",
    "# Define the path to the CSV file and the output table name\n",
    "dem_output_table = \"Demographics_data_table\"\n",
    "\n",
    "# Convert CSV to Arc Table \n",
    "arcpy.TableToTable_conversion(demographics_csv, gdb_path, dem_output_table)\n",
    "\n",
    "# Ensure 'GEO_ID' is text and properly formatted\n",
    "arcpy.management.AddField(dem_output_table, \"GEO_ID_TEXT\", \"TEXT\")\n",
    "arcpy.management.CalculateField(dem_output_table, \"GEO_ID_TEXT\", \"str(!GEO_ID!).zfill(11)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The join with poverty data was successful.\n",
      "The join with demographics data was successful.\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "## Join poverty data to census tracts to give it geographic context\n",
    "arcpy.management.JoinField(census_tracts, \"GEOID20\", \n",
    "                           \"Hennepin_pov_data\", \"povdata_FIPS\", \n",
    "                           [\"Num_in_Pov\", \"Pct_in_Pov\", \"State_Comp\"])\n",
    "\n",
    "print(\"The join with poverty data was successful.\")\n",
    "\n",
    "## Join demographics data to census tracts to give it geographic context\n",
    "arcpy.management.JoinField(census_tracts, \"GEOID20\", \n",
    "                           \"Demographics_data_table\", \"GEO_ID_TEXT\", \n",
    "                           [\"Per_White\", \"Per_Minor\"])\n",
    "\n",
    "print(\"The join with demographics data was successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial join and aggregation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "# Perform Spatial Join Between Census Tracts and Parcels\n",
    "parcels_pollution_poverty_race = os.path.join(gdb_path, \"parcels_pollution_poverty_race\")\n",
    "arcpy.analysis.SpatialJoin(\"parcels_with_pollution_count\", \"Census2020TigerTract\", parcels_pollution_poverty_race, \n",
    "                           join_type=\"KEEP_ALL\", match_option=\"WITHIN\")\n",
    "\n",
    "# Aggregate the Data by PID\n",
    "aggregated_table = os.path.join(gdb_path, \"aggregated_parcels_pollution_poverty_race\")\n",
    "arcpy.analysis.Statistics(parcels_pollution_poverty_race, aggregated_table,\n",
    "                          [[\"Pct_in_Pov\", \"MAX\"], [\"Num_in_Pov\", \"MAX\"], [\"State_Comp\", \"FIRST\"], [\"Per_Minor\", \"MAX\"]],\n",
    "                          \"PID\")\n",
    "\n",
    "# Join the Aggregated Data Back to the Parcels\n",
    "parcels_updated = os.path.join(gdb_path, \"parcels_updated\")\n",
    "arcpy.management.JoinField(parcels_pollution_poverty_race, \"PID\", aggregated_table, \"PID\",\n",
    "                           [\"MAX_Pct_in_Pov\", \"MAX_Num_in_Pov\", \"FIRST_State_Comp\", \"MAX_Per_Minor\"])\n",
    "\n",
    "# Save the final output as a new layer\n",
    "arcpy.management.CopyFeatures(parcels_pollution_poverty_race, parcels_updated)\n",
    "\n",
    "# Delete the proginal parcels_pollution_poverty layer from the map\n",
    "if arcpy.Exists(\"parcels_pollution_poverty_race\"):\n",
    "    arcpy.management.Delete(\"parcels_pollution_poverty_race\")\n",
    "\n",
    "print(\"Spatial join and aggregation completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning completed successfully.\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "# Clean parcel data\n",
    "\n",
    "# List of fields to keep\n",
    "fields_to_keep = ['FID', 'OBJECTID_1','Shape_Area', 'Shape_Length','Shape', 'OBJECTID', 'PID', 'LAT', 'LON', 'ShapeSTAre', 'ShapeSTLen', 'pts_in', 'dist_near', 'MAX_Pct_in_Pov', 'MAX_Per_Minor']\n",
    "\n",
    "# Get the fields from the parcels_updated layer\n",
    "fields_in_table = arcpy.ListFields(\"parcels_updated\")\n",
    "\n",
    "# Identify fields to delete\n",
    "fields_to_delete = [field.name for field in fields_in_table if field.name not in fields_to_keep]\n",
    "\n",
    "# Delete the unwanted fields\n",
    "if fields_to_delete:\n",
    "    arcpy.management.DeleteField(\"parcels_updated\", fields_to_delete)\n",
    "\n",
    "print(\"Cleaning completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pollution scores calculated and updated successfully.\n"
     ]
    }
   ],
   "source": [
    "## Step 4: Calculate Scores and Rank Parcels \n",
    "\n",
    "# Define pollution scoring function\n",
    "\n",
    "# Calculate the maximum values for 'pts_in' and 'dist_near'\n",
    "max_within = None\n",
    "max_distance = None\n",
    "\n",
    "with arcpy.da.SearchCursor(parcels_updated, [\"pts_in\", \"dist_near\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:\n",
    "            max_within = max(max_within, row[0]) if max_within is not None else row[0]\n",
    "        if row[1] is not None:\n",
    "            max_distance = max(max_distance, row[1]) if max_distance is not None else row[1]\n",
    "\n",
    "# Define the scoring function\n",
    "def calculate_pollution_score(pts_in, dist_near):\n",
    "    if pts_in is None or dist_near is None:\n",
    "        return 0\n",
    "    if pts_in > 0:\n",
    "        return 5 + (pts_in / max_within) * 5\n",
    "    else:\n",
    "        distance_score = 5 - (dist_near / max_distance * 5)\n",
    "        return max(distance_score, 0)\n",
    "\n",
    "# Add a new field for the pollution score\n",
    "pollution_score_field = \"pollution_score\"\n",
    "if not arcpy.ListFields(parcels_updated, pollution_score_field):\n",
    "    arcpy.management.AddField(parcels_updated, pollution_score_field, \"DOUBLE\")\n",
    "\n",
    "# Calculate and update the pollution score for each parcel\n",
    "with arcpy.da.UpdateCursor(parcels_updated, [\"pts_in\", \"dist_near\", pollution_score_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        row[2] = round(calculate_pollution_score(row[0], row[1]), 2)\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Pollution scores calculated and updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poverty scores calculated and updated successfully.\n"
     ]
    }
   ],
   "source": [
    "## Step 4: Calculate Scores and Rank Parcels \n",
    "\n",
    "# Define poverty scoring function\n",
    "\n",
    "# Define the scoring function\n",
    "def calculate_poverty_score(MAX_Pct_in_Pov):\n",
    "    if MAX_Pct_in_Pov is None:\n",
    "        return 0\n",
    "    return (MAX_Pct_in_Pov / 100) * 10\n",
    "\n",
    "# Add a new field for the poverty score\n",
    "poverty_score_field = \"poverty_score\"\n",
    "if not arcpy.ListFields(parcels_updated, poverty_score_field):\n",
    "    arcpy.management.AddField(parcels_updated, poverty_score_field, \"DOUBLE\")\n",
    "\n",
    "# Calculate and update the poverty score for each parcel\n",
    "with arcpy.da.UpdateCursor(parcels_updated, [\"MAX_Pct_in_Pov\", poverty_score_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        row[1] = round(calculate_poverty_score(row[0]), 2)\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Poverty scores calculated and updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographics scores calculated and updated successfully.\n"
     ]
    }
   ],
   "source": [
    "## Step 4: Calculate Scores and Rank Parcels \n",
    "\n",
    "# Define demographics scoring function\n",
    "\n",
    "# Define the scoring function\n",
    "def calculate_demographics_score(MAX_Per_Minor):\n",
    "    if MAX_Per_Minor is None:\n",
    "        return 0\n",
    "    return (MAX_Per_Minor / 100) * 10\n",
    "\n",
    "# Add a new field for the demographics score\n",
    "demographics_score_field = \"demographics_score\"\n",
    "if not arcpy.ListFields(parcels_updated, demographics_score_field):\n",
    "    arcpy.management.AddField(parcels_updated, demographics_score_field, \"DOUBLE\")\n",
    "\n",
    "# Calculate and update the demographics score for each parcel\n",
    "with arcpy.da.UpdateCursor(parcels_updated, [\"MAX_Per_Minor\", demographics_score_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        row[1] = round(calculate_demographics_score(row[0]), 2)\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Demographics scores calculated and updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite scores calculated and updated successfully.\n"
     ]
    }
   ],
   "source": [
    "## Step 4: Calculate Scores and Rank Parcels \n",
    "\n",
    "# Original Weighting criteria\n",
    "pollution_weight = 0.50\n",
    "poverty_weight = 0.25\n",
    "demographics_weight = 0.25\n",
    "\n",
    "\n",
    "## Overall Score Calculation\n",
    "\n",
    "# Add a new field for the composite score\n",
    "composite_score_field = \"composite_score\"\n",
    "if not arcpy.ListFields(parcels_updated, composite_score_field):\n",
    "    arcpy.management.AddField(parcels_updated, composite_score_field, \"DOUBLE\")\n",
    "\n",
    "# Calculate and update the composite score for each parcel\n",
    "with arcpy.da.UpdateCursor(parcels_updated, [\"pollution_score\", \"poverty_score\", \"demographics_score\", composite_score_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        pollution_score = row[0] if row[0] is not None else 0\n",
    "        poverty_score = row[1] if row[1] is not None else 0\n",
    "        demographics_score = row[2] if row[2] is not None else 0\n",
    "        composite_score = ((pollution_score * pollution_weight) +\n",
    "                           (poverty_score * poverty_weight) +\n",
    "                           (demographics_score * demographics_weight))\n",
    "        row[3] = round(composite_score, 2)\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Composite scores calculated and updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking completed successfully.\n"
     ]
    }
   ],
   "source": [
    "## Step 4: Calculate Scores and Rank Parcels\n",
    "\n",
    "# Add a new field for rank\n",
    "rank_field = \"rank\"\n",
    "if not arcpy.ListFields(parcels_updated, rank_field):\n",
    "    arcpy.management.AddField(parcels_updated, rank_field, \"LONG\")\n",
    "\n",
    "# Create a list to store composite scores and their OBJECTIDs\n",
    "scores = []\n",
    "\n",
    "# Collect composite scores and OBJECTIDs\n",
    "with arcpy.da.SearchCursor(parcels_updated, [\"OBJECTID\", \"composite_score\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        scores.append((row[0], row[1]))\n",
    "\n",
    "# Sort the list by composite scores in descending order\n",
    "scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Assign ranks\n",
    "rank_dict = {obj_id: rank + 1 for rank, (obj_id, score) in enumerate(scores)}\n",
    "\n",
    "# Update the rank field in the feature class\n",
    "with arcpy.da.UpdateCursor(parcels_updated, [\"OBJECTID\", rank_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        row[1] = rank_dict[row[0]]\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Ranking completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity analysis completed. Composite scores for different schemes have been calculated and updated.\n"
     ]
    }
   ],
   "source": [
    "## Step 5: Sensitivity Analysis \n",
    "\n",
    "# Define the weight schemes of the sensitivity analysis\n",
    "weight_schemes = {\n",
    "    \"Scheme_1\": {\"pollution\": 0.50, \"poverty\": 0.25, \"demographics\": 0.25}, # Original weighting scheme\n",
    "    \"Scheme_2\": {\"pollution\": 0.34, \"poverty\": 0.33, \"demographics\": 0.33}, # Nearly equal weighting scheme to all three variables (pollution given 0.01 heavier weight to sum to 1)\n",
    "    \"Scheme_3\": {\"pollution\": 0.10, \"poverty\": 0.45, \"demographics\": 0.45}, # Pollution only weighted at 0.1, giving almost all (0.9) priority evenly to poverty and demographics\n",
    "    \"Scheme_4\": {\"pollution\": 0.15, \"poverty\": 0.15, \"demographics\": 0.70}, # Demographics weighted at 0.5 \n",
    "    \"Scheme_5\": {\"pollution\": 0.15, \"poverty\": 0.70, \"demographics\": 0.15}, # Poverty weighted at 0.5\n",
    "}\n",
    "\n",
    "# Add new fields for each composite score scheme\n",
    "for scheme in weight_schemes.keys():\n",
    "    composite_field = f\"composite_{scheme}\"\n",
    "    if not arcpy.ListFields(parcels_updated, composite_field):\n",
    "        arcpy.management.AddField(parcels_updated, composite_field, \"DOUBLE\")\n",
    "\n",
    "# Recalculate composite scores for each scheme and update the feature class\n",
    "for scheme, weights in weight_schemes.items():\n",
    "    composite_field = f\"composite_{scheme}\"\n",
    "    pollution_weight = weights[\"pollution\"]\n",
    "    poverty_weight = weights[\"poverty\"]\n",
    "    demographics_weight = weights[\"demographics\"]\n",
    "\n",
    "    with arcpy.da.UpdateCursor(parcels_updated, [\"pollution_score\", \"poverty_score\", \"demographics_score\", composite_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            pollution_score = row[0] if row[0] is not None else 0\n",
    "            poverty_score = row[1] if row[1] is not None else 0\n",
    "            demographics_score = row[2] if row[2] is not None else 0\n",
    "            composite_score = (pollution_score * pollution_weight +\n",
    "                               poverty_score * poverty_weight +\n",
    "                               demographics_score * demographics_weight)\n",
    "            row[3] = round(composite_score, 2)\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "print(\"Sensitivity analysis completed. Composite scores for different schemes have been calculated and updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1 hours, 1 minutes, 19.41 seconds\n"
     ]
    }
   ],
   "source": [
    "## Step 6: Calculate total time\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "hours = int(total_time // 3600)\n",
    "minutes = int((total_time % 3600) // 60)\n",
    "seconds = total_time % 60\n",
    "print(f\"Total time: {hours} hours, {minutes} minutes, {seconds:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
